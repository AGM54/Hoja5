{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIVE BAYES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 modelo de regressión bates ingenuo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.684931506849315%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "#se usa el gausian NB dado que la data no es discreta , sino continua\n",
    "data = pd.read_csv('train.csv')\n",
    "df = pd.read_csv('train.csv')\n",
    "numeric_features = data.select_dtypes(include=['int64', 'float64']).columns.drop(['Id','SalePrice'])\n",
    "#mimsa data de modelos lineales, y de arbol\n",
    "X = df[numeric_features]\n",
    "y = df['SalePrice']\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_predictor = GaussianNB()\n",
    "nb_predictor.fit(X_train, y_train)\n",
    "y_pred = nb_predictor.predict(X_test)\n",
    "\n",
    "accuracy_report = accuracy_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "print(f\"Accuracy of model: {accuracy_report*100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analice los resultados del modelo de regresión. ¿Qué tan bien le fue prediciendo?\n",
    "\n",
    "El resultado es pésimo , no es del 1%, pues el modelo requiere más preparación de los datos y naive bayes es para clasificacion no para predecir una variable de respuesta directamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Compare los resultados con el modelo de regresión lineal y el árbol de regresión que hizo en las hojas pasadas. ¿Cuál funcionó mejor?\n",
    "\n",
    "el que funcionó mejor es la regresión lineal con una precisión del 80% (R^2) , pues es el más optimo para predicciones de valores de una variable respuesta, mientras que naive bayes y arbol es para clasificacion, sin embargo el arbol obtuvo un accuracy de 72%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Haga un modelo de clasificación, use la variable categórica que hizo con el precio de las  casas (barata, media y cara) como variable respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6917808219178082\n",
      "Confusion Matrix:\n",
      "[[64  0  6]\n",
      " [ 0 76  5]\n",
      " [35 44 62]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Caras       0.65      0.91      0.76        70\n",
      "  Económicas       0.63      0.94      0.76        81\n",
      " Intermedias       0.85      0.44      0.58       141\n",
      "\n",
      "    accuracy                           0.69       292\n",
      "   macro avg       0.71      0.76      0.70       292\n",
      "weighted avg       0.74      0.69      0.67       292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Creación de la variable categórica 'PriceCategory'\n",
    "p25 = data['SalePrice'].quantile(0.25)\n",
    "p75 = data['SalePrice'].quantile(0.75)\n",
    "data['PriceCategory'] = pd.cut(data['SalePrice'], bins=[0, p25, p75, float('inf')], labels=['Económicas', 'Intermedias', 'Caras'], right=False)\n",
    "\n",
    "# Preprocesamiento de variables categóricas\n",
    "categorical_features = data.select_dtypes(include=['object']).columns\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "encoded_categorical_data = pd.DataFrame(one_hot_encoder.fit_transform(data[categorical_features]))\n",
    "encoded_categorical_data.columns = one_hot_encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Concatenación de características numéricas y categóricas codificadas\n",
    "numeric_features = data.select_dtypes(include=['int64', 'float64']).columns.drop('SalePrice')\n",
    "X = pd.concat([data[numeric_features], encoded_categorical_data], axis=1)\n",
    "y = data['PriceCategory']\n",
    "\n",
    "# Imputación de valores faltantes\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "X[numeric_features] = numeric_imputer.fit_transform(X[numeric_features])\n",
    "X[encoded_categorical_data.columns] = categorical_imputer.fit_transform(X[encoded_categorical_data.columns])\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Utilice los modelos con el conjunto de prueba y determine la eficiencia del algoritmo para  predecir y clasificar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación de Modelos de Clasificación\n",
    "\n",
    "## Modelo de Clasificación (Categorías: Baratas, Intermedias, Caras)\n",
    "\n",
    "- **Precisión (Accuracy):** 69.18%\n",
    "- **Matriz de confusión:**\n",
    "[[64 0 6]\n",
    "[ 0 76 5]\n",
    "[35 44 62]]\n",
    "\n",
    "\n",
    "\n",
    "### Informe de Clasificación\n",
    "- Clase \"Caras\": precisión de 0.65, recall de 0.91.\n",
    "- Clase \"Económicas\": precisión de 0.63, recall de 0.94.\n",
    "- Clase \"Intermedias\": precisión de 0.85, recall de 0.44.\n",
    "\n",
    "## Modelo de Naive Bayes Adaptado para Regresión (Categorías: Baratas, Intermedias, Caras)\n",
    "\n",
    "- **Precisión (Accuracy):** 56.16%\n",
    "- **Matriz de confusión:**\n",
    "[[51 43 16]\n",
    "[ 5 25 58]\n",
    "[ 1 5 88]]\n",
    "\n",
    "\n",
    "\n",
    "### Informe de Clasificación\n",
    "- Clase \"Baratas\": precisión de 0.89, recall de 0.46.\n",
    "- Clase \"Intermedias\": precisión de 0.34, recall de 0.28.\n",
    "- Clase \"Caras\": precisión de 0.54, recall de 0.94.\n",
    "\n",
    "## Comparación y Análisis\n",
    "\n",
    "- El **modelo de clasificación** tiene una **precisión general más alta (69.18%)** en comparación con el **modelo adaptado para regresión (56.16%)**.\n",
    "- En el modelo de clasificación, las clases \"Caras\" y \"Económicas\" tienen altos valores de recall, lo que indica que el modelo es bueno para identificar estas categorías. Sin embargo, la clase \"Intermedias\" tiene un recall bajo, lo que sugiere que el modelo tiene dificultades para identificar correctamente esta categoría.\n",
    "- En el modelo adaptado para regresión, la clase \"Caras\" tiene un recall muy alto (0.94), pero la clase \"Intermedias\" tiene valores bajos tanto en precisión como en recall, lo que indica una dificultad significativa para clasificar correctamente esta categoría.\n",
    "- Ambos modelos tienen un rendimiento variable en diferentes categorías, pero el **modelo de clasificación parece ser más equilibrado** en términos de precisión y recall para las tres categorías.\n",
    "\n",
    "El **modelo de clasificación** es **más eficiente para predecir y clasificar** , especialmente para las categorías \"Caras\" y \"Económicas\". El modelo adaptado para regresión tiene un rendimiento más bajo,haciendo enfásis  en la categoría \"Intermedias\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Haga un análisis de la eficiencia del modelo de clasificación usando una matriz de confusión. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[64  0  6]\n",
    " [ 0 76  5]\n",
    " [35 44 62]]\n",
    "\n",
    "\n",
    "# Análisis Detallado de la Matriz de Confusión\n",
    "\n",
    "## Clase \"Caras\"\n",
    "- **Verdaderos Positivos (TP) = 64:** El modelo clasificó correctamente 64 casas como \"Caras\".\n",
    "- **Falsos Negativos (FN) = 6:** El modelo no identificó 6 casas que eran \"Caras\".\n",
    "- **Falsos Positivos (FP) = 0:** El modelo no clasificó incorrectamente ninguna casa como \"Cara\".\n",
    "- **Análisis:** La clase \"Caras\" tiene una alta precisión y un buen recall, lo que indica que el modelo es muy confiable al identificar casas \"Caras\" y rara vez las confunde con otras categorías.\n",
    "\n",
    "## Clase \"Económicas\"\n",
    "- **Verdaderos Positivos (TP) = 76:** El modelo clasificó correctamente 76 casas como \"Económicas\".\n",
    "- **Falsos Negativos (FN) = 5:** El modelo no identificó 5 casas que eran \"Económicas\".\n",
    "- **Falsos Positivos (FP) = 0:** El modelo no clasificó incorrectamente ninguna casa como \"Económica\".\n",
    "- **Análisis:** La clase \"Económicas\" tiene una alta precisión y un buen recall, lo que indica que el modelo es muy efectivo al clasificar casas en esta categoría.\n",
    "\n",
    "## Clase \"Intermedias\"\n",
    "- **Verdaderos Positivos (TP) = 62:** El modelo clasificó correctamente 62 casas como \"Intermedias\".\n",
    "- **Falsos Negativos (FN) = 79:** El modelo no identificó 79 casas que eran \"Intermedias\".\n",
    "- **Falsos Positivos (FP) = 79:** El modelo clasificó incorrectamente 79 casas como \"Intermedias\".\n",
    "- **Análisis:** La clase \"Intermedias\" presenta el mayor desafío para el modelo, con una precisión más baja y un recall moderado. Esto indica una considerable confusión entre esta categoría y las otras.\n",
    "\n",
    "# Importancia de los Errores\n",
    "\n",
    "## Impacto de los Falsos Positivos (FP)\n",
    "- Los FP en la clase \"Intermedias\" pueden llevar a una sobreestimación de la calidad o el valor de las casas. Esto podría resultar en decisiones de inversión equivocadas.\n",
    "\n",
    "## Impacto de los Falsos Negativos (FN)\n",
    "- Los FN en la clase \"Intermedias\" pueden tener el efecto contrario, subestimando el valor de las casas que realmente pertenecen a esta categoría. Esto podría resultar en oportunidades perdidas o en la subvaloración de propiedades.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 8 Analice el modelo. ¿Cree que pueda estar sobre ajustado? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de entrenamiento: 0.7243150684931506\n",
      "Accuracy en el conjunto de prueba: 0.6917808219178082\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "print(f'Accuracy en el conjunto de entrenamiento: {train_accuracy}')\n",
    "print(f'Accuracy en el conjunto de prueba: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisión en el conjunto de entrenamiento: 72.43%\n",
    "Precisión en el conjunto de prueba: 69.18%\n",
    "La diferencia entre la precisión en el conjunto de entrenamiento y la precisión en el conjunto de prueba es relativamente pequeña ,aproximadamente 3.25%. Esto indica que el modelo está generalizando bien a los datos no vistos y no muestra signos evidentes de sobreajuste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntajes de validación cruzada: [0.6369863  0.69178082 0.73630137 0.70205479 0.71232877]\n",
      "Promedio de puntajes de validación cruzada: 0.695890410958904\n",
      "Accuracy del modelo anterior en el conjunto de prueba: 0.6917808219178082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f'Puntajes de validación cruzada: {cv_scores}')\n",
    "print(f'Promedio de puntajes de validación cruzada: {cv_scores.mean()}')\n",
    "\n",
    "\n",
    "print(f'Accuracy del modelo anterior en el conjunto de prueba: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El promedio de los puntajes de validación cruzada es ligeramente superior a la precisión del modelo anterior en el conjunto de prueba. La diferencia es pequeña, sin embargo, el modelo evaluado con validación cruzada funcionó ligeramente mejor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tanto para los modelos de regresión como de clasificación,pruebe con varios valores de los hiperparámetros, use el mejor modelo del tunneo, ¿Mejoraron los modelos? Explique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de regresión ingenuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo con los mejores hiperparámetros: 1.0273972602739725%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.drop(['Id', 'SalePrice'])\n",
    "\n",
    "X = df[numeric_features]\n",
    "y = df['SalePrice']\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_var_smoothing = best_params['var_smoothing']\n",
    "best_nb_model = GaussianNB(var_smoothing=best_var_smoothing)\n",
    "best_nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en los datos de prueba\n",
    "y_pred_test = best_nb_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Precisión del modelo con los mejores hiperparámetros: {accuracy*100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00684931506849315\n",
      "Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       35311       0.00      0.00      0.00         1\n",
      "       40000       0.00      0.00      0.00         1\n",
      "       55000       0.00      0.00      0.00         0\n",
      "       55993       0.00      0.00      0.00         1\n",
      "       60000       0.00      0.00      0.00         1\n",
      "       64500       0.00      0.00      0.00         1\n",
      "       66500       0.00      0.00      0.00         1\n",
      "       67000       0.00      0.00      0.00         2\n",
      "       68400       0.00      0.00      0.00         1\n",
      "       68500       0.00      0.00      0.00         1\n",
      "       75000       0.00      0.00      0.00         1\n",
      "       75500       0.00      0.00      0.00         1\n",
      "       79000       0.00      0.00      0.00         0\n",
      "       79500       0.00      0.00      0.00         1\n",
      "       79900       0.00      0.00      0.00         0\n",
      "       80000       0.00      0.00      0.00         0\n",
      "       81000       0.00      0.00      0.00         1\n",
      "       82000       0.00      0.00      0.00         0\n",
      "       82500       0.00      0.00      0.00         0\n",
      "       84500       0.00      0.00      0.00         1\n",
      "       84900       0.00      0.00      0.00         1\n",
      "       85000       0.00      0.00      0.00         1\n",
      "       86000       0.00      0.00      0.00         2\n",
      "       87000       0.00      0.00      0.00         0\n",
      "       88000       0.00      0.00      0.00         0\n",
      "       89471       0.00      0.00      0.00         1\n",
      "       90000       0.00      0.00      0.00         0\n",
      "       91000       0.00      0.00      0.00         1\n",
      "       91300       0.00      0.00      0.00         1\n",
      "       92000       0.00      0.00      0.00         1\n",
      "       93000       0.00      0.00      0.00         0\n",
      "       93500       0.00      0.00      0.00         2\n",
      "       97000       0.00      0.00      0.00         1\n",
      "       98000       0.00      0.00      0.00         0\n",
      "      100000       0.00      0.00      0.00         0\n",
      "      101800       0.00      0.00      0.00         1\n",
      "      102000       0.00      0.00      0.00         1\n",
      "      102776       0.00      0.00      0.00         1\n",
      "      103200       0.00      0.00      0.00         1\n",
      "      104000       0.00      0.00      0.00         1\n",
      "      105000       0.00      0.00      0.00         0\n",
      "      105900       0.00      0.00      0.00         1\n",
      "      106000       0.00      0.00      0.00         0\n",
      "      107000       0.00      0.00      0.00         1\n",
      "      107500       0.00      0.00      0.00         2\n",
      "      107900       0.00      0.00      0.00         1\n",
      "      108000       0.00      0.00      0.00         1\n",
      "      108480       0.00      0.00      0.00         1\n",
      "      108959       0.00      0.00      0.00         1\n",
      "      109000       0.00      0.00      0.00         1\n",
      "      109008       0.00      0.00      0.00         1\n",
      "      109500       0.00      0.00      0.00         1\n",
      "      109900       0.00      0.00      0.00         0\n",
      "      110000       0.00      0.00      0.00         1\n",
      "      112000       0.00      0.00      0.00         1\n",
      "      112500       0.00      0.00      0.00         0\n",
      "      113000       0.00      0.00      0.00         2\n",
      "      114500       0.00      0.00      0.00         1\n",
      "      115000       0.00      0.00      0.00         6\n",
      "      116000       0.00      0.00      0.00         0\n",
      "      117000       0.00      0.00      0.00         0\n",
      "      117500       0.00      0.00      0.00         1\n",
      "      118000       0.00      0.00      0.00         1\n",
      "      118400       0.00      0.00      0.00         1\n",
      "      118500       0.00      0.00      0.00         1\n",
      "      118858       0.00      0.00      0.00         1\n",
      "      119000       0.00      0.00      0.00         2\n",
      "      119500       0.00      0.00      0.00         2\n",
      "      120000       0.00      0.00      0.00         1\n",
      "      120500       0.00      0.00      0.00         0\n",
      "      122500       0.00      0.00      0.00         1\n",
      "      123000       0.00      0.00      0.00         2\n",
      "      124000       0.00      0.00      0.00         1\n",
      "      124500       0.00      0.00      0.00         2\n",
      "      124900       0.00      0.00      0.00         1\n",
      "      125500       0.00      0.00      0.00         1\n",
      "      126000       0.00      0.00      0.00         1\n",
      "      127000       0.00      0.00      0.00         3\n",
      "      127500       0.00      0.00      0.00         1\n",
      "      128000       0.00      0.00      0.00         0\n",
      "      128200       0.00      0.00      0.00         1\n",
      "      128500       0.00      0.00      0.00         1\n",
      "      128950       0.00      0.00      0.00         1\n",
      "      129000       0.00      0.00      0.00         1\n",
      "      129500       0.00      0.00      0.00         0\n",
      "      129900       0.00      0.00      0.00         1\n",
      "      130000       0.00      0.00      0.00         2\n",
      "      130250       0.00      0.00      0.00         1\n",
      "      131400       0.00      0.00      0.00         1\n",
      "      131500       0.00      0.00      0.00         0\n",
      "      132000       0.00      0.00      0.00         2\n",
      "      132500       0.00      0.00      0.00         1\n",
      "      133000       0.00      0.00      0.00         2\n",
      "      133900       0.00      0.00      0.00         1\n",
      "      134000       0.00      0.00      0.00         1\n",
      "      134432       0.00      0.00      0.00         1\n",
      "      134500       0.00      0.00      0.00         1\n",
      "      135000       0.00      0.00      0.00         4\n",
      "      135500       0.00      0.00      0.00         2\n",
      "      135750       0.00      0.00      0.00         1\n",
      "      136000       0.00      0.00      0.00         1\n",
      "      136500       0.00      0.00      0.00         2\n",
      "      137000       0.00      0.00      0.00         1\n",
      "      137500       0.00      0.00      0.00         3\n",
      "      138000       0.00      0.00      0.00         1\n",
      "      139000       0.00      0.00      0.00         1\n",
      "      139400       0.00      0.00      0.00         0\n",
      "      140000       0.00      0.00      0.00         5\n",
      "      141000       0.00      0.00      0.00         3\n",
      "      142000       0.00      0.00      0.00         0\n",
      "      142500       0.00      0.00      0.00         1\n",
      "      143000       0.00      0.00      0.00         3\n",
      "      143500       0.00      0.00      0.00         1\n",
      "      144000       0.00      0.00      0.00         4\n",
      "      144500       0.00      0.00      0.00         2\n",
      "      145000       0.00      0.00      0.00         4\n",
      "      146000       0.00      0.00      0.00         1\n",
      "      147000       0.00      0.00      0.00         2\n",
      "      148000       0.00      0.00      0.00         0\n",
      "      148500       0.00      0.00      0.00         1\n",
      "      149000       0.00      0.00      0.00         1\n",
      "      149500       0.00      0.00      0.00         1\n",
      "      149900       0.00      0.00      0.00         0\n",
      "      150000       0.00      0.00      0.00         0\n",
      "      151000       0.00      0.00      0.00         1\n",
      "      152000       0.00      0.00      0.00         1\n",
      "      153500       0.00      0.00      0.00         2\n",
      "      153575       0.00      0.00      0.00         1\n",
      "      153900       0.00      0.00      0.00         1\n",
      "      154000       0.20      1.00      0.33         1\n",
      "      154300       0.00      0.00      0.00         1\n",
      "      154500       0.00      0.00      0.00         1\n",
      "      154900       0.00      0.00      0.00         1\n",
      "      155000       0.00      0.00      0.00         3\n",
      "      155835       0.00      0.00      0.00         1\n",
      "      155900       0.00      0.00      0.00         1\n",
      "      156000       0.00      0.00      0.00         1\n",
      "      156500       0.00      0.00      0.00         1\n",
      "      157000       0.00      0.00      0.00         0\n",
      "      158000       0.00      0.00      0.00         1\n",
      "      159000       0.00      0.00      0.00         1\n",
      "      160000       0.00      0.00      0.00         2\n",
      "      162900       0.00      0.00      0.00         1\n",
      "      163500       0.00      0.00      0.00         1\n",
      "      164000       0.00      0.00      0.00         0\n",
      "      165000       0.00      0.00      0.00         2\n",
      "      165600       0.00      0.00      0.00         1\n",
      "      167000       0.00      0.00      0.00         0\n",
      "      169000       0.00      0.00      0.00         1\n",
      "      169990       0.00      0.00      0.00         1\n",
      "      171000       0.00      0.00      0.00         1\n",
      "      172500       0.00      0.00      0.00         2\n",
      "      173000       0.00      0.00      0.00         2\n",
      "      173500       0.00      0.00      0.00         1\n",
      "      174000       0.00      0.00      0.00         0\n",
      "      175000       0.00      0.00      0.00         3\n",
      "      175900       0.00      0.00      0.00         1\n",
      "      176000       0.00      0.00      0.00         2\n",
      "      177000       0.00      0.00      0.00         0\n",
      "      177500       0.00      0.00      0.00         1\n",
      "      178000       0.00      0.00      0.00         1\n",
      "      179900       0.00      0.00      0.00         2\n",
      "      180000       0.33      0.50      0.40         2\n",
      "      180500       0.00      0.00      0.00         0\n",
      "      181000       0.00      0.00      0.00         2\n",
      "      181134       0.00      0.00      0.00         1\n",
      "      183500       0.00      0.00      0.00         1\n",
      "      183900       0.00      0.00      0.00         1\n",
      "      185000       0.00      0.00      0.00         2\n",
      "      185750       0.00      0.00      0.00         1\n",
      "      185900       0.00      0.00      0.00         1\n",
      "      186500       0.00      0.00      0.00         0\n",
      "      187100       0.00      0.00      0.00         1\n",
      "      187500       0.00      0.00      0.00         1\n",
      "      188000       0.00      0.00      0.00         0\n",
      "      189000       0.00      0.00      0.00         1\n",
      "      190000       0.00      0.00      0.00         1\n",
      "      192000       0.00      0.00      0.00         1\n",
      "      192140       0.00      0.00      0.00         1\n",
      "      192500       0.00      0.00      0.00         1\n",
      "      193000       0.00      0.00      0.00         0\n",
      "      194000       0.00      0.00      0.00         1\n",
      "      194201       0.00      0.00      0.00         1\n",
      "      194500       0.00      0.00      0.00         1\n",
      "      195000       0.00      0.00      0.00         0\n",
      "      195400       0.00      0.00      0.00         1\n",
      "      196000       0.00      0.00      0.00         2\n",
      "      197000       0.00      0.00      0.00         2\n",
      "      197900       0.00      0.00      0.00         1\n",
      "      199900       0.00      0.00      0.00         0\n",
      "      200000       0.00      0.00      0.00         0\n",
      "      200500       0.00      0.00      0.00         1\n",
      "      200624       0.00      0.00      0.00         1\n",
      "      201000       0.00      0.00      0.00         1\n",
      "      202500       0.00      0.00      0.00         1\n",
      "      203000       0.00      0.00      0.00         0\n",
      "      204900       0.00      0.00      0.00         1\n",
      "      205000       0.00      0.00      0.00         2\n",
      "      207000       0.00      0.00      0.00         1\n",
      "      207500       0.00      0.00      0.00         0\n",
      "      208900       0.00      0.00      0.00         1\n",
      "      210000       0.00      0.00      0.00         1\n",
      "      213000       0.00      0.00      0.00         1\n",
      "      213500       0.00      0.00      0.00         1\n",
      "      214000       0.00      0.00      0.00         2\n",
      "      215000       0.00      0.00      0.00         0\n",
      "      217500       0.00      0.00      0.00         1\n",
      "      219500       0.00      0.00      0.00         1\n",
      "      220000       0.00      0.00      0.00         1\n",
      "      223500       0.00      0.00      0.00         0\n",
      "      224900       0.00      0.00      0.00         1\n",
      "      225000       0.00      0.00      0.00         2\n",
      "      226000       0.00      0.00      0.00         1\n",
      "      227000       0.00      0.00      0.00         0\n",
      "      230000       0.00      0.00      0.00         2\n",
      "      231500       0.00      0.00      0.00         0\n",
      "      232000       0.00      0.00      0.00         0\n",
      "      235000       0.00      0.00      0.00         0\n",
      "      236000       0.00      0.00      0.00         1\n",
      "      239000       0.00      0.00      0.00         1\n",
      "      239500       0.00      0.00      0.00         1\n",
      "      240000       0.00      0.00      0.00         1\n",
      "      241500       0.00      0.00      0.00         1\n",
      "      242000       0.00      0.00      0.00         1\n",
      "      243000       0.00      0.00      0.00         1\n",
      "      244000       0.00      0.00      0.00         1\n",
      "      244400       0.00      0.00      0.00         1\n",
      "      246578       0.00      0.00      0.00         1\n",
      "      250000       0.00      0.00      0.00         1\n",
      "      253000       0.00      0.00      0.00         1\n",
      "      253293       0.00      0.00      0.00         1\n",
      "      254000       0.00      0.00      0.00         1\n",
      "      255000       0.00      0.00      0.00         2\n",
      "      260000       0.00      0.00      0.00         3\n",
      "      262500       0.00      0.00      0.00         1\n",
      "      264132       0.00      0.00      0.00         1\n",
      "      266000       0.00      0.00      0.00         1\n",
      "      270000       0.00      0.00      0.00         0\n",
      "      271000       0.00      0.00      0.00         1\n",
      "      275000       0.00      0.00      0.00         2\n",
      "      276000       0.00      0.00      0.00         1\n",
      "      277000       0.00      0.00      0.00         1\n",
      "      280000       0.00      0.00      0.00         1\n",
      "      283463       0.00      0.00      0.00         1\n",
      "      284000       0.00      0.00      0.00         2\n",
      "      285000       0.00      0.00      0.00         1\n",
      "      287000       0.00      0.00      0.00         1\n",
      "      290000       0.00      0.00      0.00         0\n",
      "      293077       0.00      0.00      0.00         1\n",
      "      297000       0.00      0.00      0.00         1\n",
      "      301000       0.00      0.00      0.00         1\n",
      "      305000       0.00      0.00      0.00         1\n",
      "      310000       0.00      0.00      0.00         1\n",
      "      311500       0.00      0.00      0.00         1\n",
      "      311872       0.00      0.00      0.00         1\n",
      "      315000       0.00      0.00      0.00         1\n",
      "      315500       0.00      0.00      0.00         1\n",
      "      317000       0.00      0.00      0.00         1\n",
      "      318061       0.00      0.00      0.00         1\n",
      "      320000       0.00      0.00      0.00         0\n",
      "      325000       0.00      0.00      0.00         1\n",
      "      335000       0.00      0.00      0.00         0\n",
      "      337500       0.00      0.00      0.00         1\n",
      "      340000       0.00      0.00      0.00         0\n",
      "      341000       0.00      0.00      0.00         1\n",
      "      345000       0.00      0.00      0.00         0\n",
      "      348000       0.00      0.00      0.00         1\n",
      "      360000       0.00      0.00      0.00         1\n",
      "      367294       0.00      0.00      0.00         1\n",
      "      369900       0.00      0.00      0.00         1\n",
      "      385000       0.00      0.00      0.00         0\n",
      "      395000       0.00      0.00      0.00         1\n",
      "      403000       0.00      0.00      0.00         1\n",
      "      438780       0.00      0.00      0.00         1\n",
      "      451950       0.00      0.00      0.00         1\n",
      "      465000       0.00      0.00      0.00         1\n",
      "      556581       0.00      0.00      0.00         1\n",
      "      611657       0.00      0.00      0.00         1\n",
      "      755000       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.01       292\n",
      "   macro avg       0.00      0.01      0.00       292\n",
      "weighted avg       0.00      0.01      0.00       292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer \n",
    "# Leer el conjunto de datos\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Crear la variable categórica 'PriceCategory'\n",
    "p25 = data['SalePrice'].quantile(0.25)\n",
    "p75 = data['SalePrice'].quantile(0.75)\n",
    "data['PriceCategory'] = pd.cut(data['SalePrice'], bins=[0, p25, p75, float('inf')], labels=['Económicas', 'Intermedias', 'Caras'], right=False)\n",
    "\n",
    "\n",
    "\n",
    "# Definir características categóricas excluyendo 'PriceCategory'\n",
    "categorical_features = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Definir características numéricas\n",
    "numeric_features = data.select_dtypes(include=['int64', 'float64']).columns.drop(['Id', 'SalePrice'])\n",
    "\n",
    "# Preprocesamiento de características numéricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocesamiento de características categóricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "# Combinar preprocesadores\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X = df[numeric_features]\n",
    "y = df['SalePrice']\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo Naive Bayes Gaussiano\n",
    "model = GaussianNB()\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluación del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "print('Classification Report:')\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de clasificacion no mejora, sino empeora perdiendo toda su accuracy. Y el de regresión aumenta a 1.02%, pero igualmente es insignificante sus predicciones, pues no es viable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare la eficiencia del algoritmo con el resultado obtenido con el árbol de decisión (el de clasificación) y el modelo de random forest que hizo en la hoja pasada. ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 0.011999130249023438 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "print(f\"Tiempo de entrenamiento: {end_time - start_time} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rendimiento: El modelo de Random Forest para regresión tiene un R² de 0.8899, lo que indica un buen ajuste al conjunto de datos. En comparación, el modelo Naive Bayes para clasificación tiene una precisión del 69.18%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
